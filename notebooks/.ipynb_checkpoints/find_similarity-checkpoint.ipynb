{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1744, 4)\n",
      "(58, 12)\n",
      "(58, 4)\n",
      "(1802, 4)\n",
      "1802\n"
     ]
    }
   ],
   "source": [
    "ANNOTATIONS_DIR = '../data/annotations/annotations averaged per song/song_level'\n",
    "MFCC_DIR = '../data/mfcc'\n",
    "METADATA_DIR = '../data/metadata'\n",
    "\n",
    "df = pd.read_csv(f\"{ANNOTATIONS_DIR}/static_annotations_averaged_songs_1_2000.csv\", index_col='song_id')\n",
    "print(df.shape)\n",
    "df2 = pd.read_csv(f\"{ANNOTATIONS_DIR}/static_annotations_averaged_songs_2000_2058.csv\", index_col='song_id')\n",
    "print(df2.shape)\n",
    "for column in df2.columns.values:\n",
    "   if column not in df.columns.values:\n",
    "       df2 = df2.drop(column, axis = 1)\n",
    "print(df2.shape)\n",
    "df = df.append(df2)\n",
    "print(df.values.shape)\n",
    "song_ids = df.index.tolist()\n",
    "print(len(song_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1744, 4)\n",
      "(58, 12)\n",
      "(58, 4)\n",
      "(1802, 4)\n",
      "1802\n"
     ]
    }
   ],
   "source": [
    "##Find Metadata Similarity\n",
    "def createdic():\n",
    "    df = pd.read_csv(f\"{ANNOTATIONS_DIR}/static_annotations_averaged_songs_1_2000.csv\", index_col='song_id')\n",
    "    print(df.shape)\n",
    "    df2 = pd.read_csv(f\"{ANNOTATIONS_DIR}/static_annotations_averaged_songs_2000_2058.csv\", index_col='song_id')\n",
    "    print(df2.shape)\n",
    "    for column in df2.columns.values:\n",
    "        if column not in df.columns.values:\n",
    "            df2 = df2.drop(column, axis = 1)\n",
    "    print(df2.shape)\n",
    "    df = df.append(df2)\n",
    "    print(df.values.shape)\n",
    "    song_ids = df.index.tolist()\n",
    "    print(len(song_ids))\n",
    "    df_meta1=pd.read_csv(f\"{METADATA_DIR}/metadata_2013.csv\")\n",
    "    df_meta2=pd.read_csv(f\"{METADATA_DIR}/metadata_2014.csv\")\n",
    "    df_meta3=pd.read_csv(f\"{METADATA_DIR}/metadata_2015_2.csv\")\n",
    "    dic={}\n",
    "    id_col1=df_meta1.columns[0]\n",
    "    id_col2=df_meta2.columns[0]\n",
    "    id_col3=df_meta3.columns[0]\n",
    "    for song_id in song_ids:\n",
    "        if song_id<=1000:\n",
    "            str1=''\n",
    "            for x in df_meta1.loc[df_meta1[id_col1]==song_id].values[0]:\n",
    "                str1+=str(x)\n",
    "            str1 = str1.replace('nan', ' ')\n",
    "            str1 = str1.replace('.mp3', '')\n",
    "            str1 = str1.replace(str(song_id), ' ')\n",
    "            dic[song_id]=str1.replace('\\t', ' ')\n",
    "        elif song_id<=2000:\n",
    "            str1=''\n",
    "            for x in df_meta2.loc[df_meta2[id_col2]==song_id].values[0]:\n",
    "                if(str(x) == 'nan'): continue\n",
    "                str1+=str(x)\n",
    "            str1 = str1.replace('nan', ' ')\n",
    "            str1 = str1.replace('.mp3', '')\n",
    "            str1 = str1.replace(str(song_id), ' ')\n",
    "            dic[song_id]=str1.replace('\\t', ' ')\n",
    "        else:\n",
    "            str1=''\n",
    "            for x in df_meta3.loc[df_meta3[id_col3]==song_id].values[0]:\n",
    "                if(str(x) == 'nan'): continue\n",
    "                str1+=str(x)\n",
    "            str1 = str1.replace('nan', ' ')\n",
    "            str1 = str1.replace('.mp3', '')\n",
    "            str1 = str1.replace(str(song_id), ' ')\n",
    "            dic[song_id]=str1.replace('\\t', ' ')\n",
    "    return dic\n",
    "song_metadic=createdic()\n",
    "#print(song_metadic)\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "def find_metadata_similarity(song_id):\n",
    "    metascore=[]\n",
    "    for key in song_metadic.keys():\n",
    "        if(key == song_id): continue\n",
    "        metascore.append([key, SequenceMatcher(None, song_metadic[key], song_metadic[song_id]).ratio()])\n",
    "    return metascore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Find Emotion Similarity\n",
    "def find_emotion_similarity(song_id):\n",
    "    this_song = np.array([df.loc[song_id].values[0], df.loc[song_id].values[2]])\n",
    "    sim_scores = []\n",
    "    for song in song_ids:\n",
    "        if(song_id == song): continue\n",
    "        curr_song = np.array([df.loc[song].values[0], df.loc[song].values[2]])\n",
    "        dist = np.linalg.norm(this_song-curr_song)\n",
    "        sim_scores.append([song, dist])\n",
    "    return sim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Find Combined Similarity\n",
    "def similarity(song_id):\n",
    "    metadata_sim = np.array(find_metadata_similarity(song_id))\n",
    "    emotion_sim = np.array(find_emotion_similarity(song_id))\n",
    "    MAX_EMOTION = max(emotion_sim[:, 1])\n",
    "    MIN_EMOTION = min(emotion_sim[:, 1])\n",
    "    emotion_sim[:, 1] = (emotion_sim[:, 1] - MIN_EMOTION)/(MAX_EMOTION - MIN_EMOTION)\n",
    "    MAX_METSCORE = max(metadata_sim[:, 1])\n",
    "    MIN_METSCORE = min(metadata_sim[:, 1])\n",
    "    metadata_sim[:, 1] = (metadata_sim[:, 1] - MIN_METSCORE)/(MAX_METSCORE - MIN_METSCORE)\n",
    "    combined = {}\n",
    "    for song in song_ids:\n",
    "        if(song == song_id): continue\n",
    "        metadata_score = metadata_sim[metadata_sim[:, 0] == song][0,1]\n",
    "        emotion_score = emotion_sim[emotion_sim[:, 0] == song][0,1]\n",
    "        combined_score = 0.5*(1-emotion_score) + 0.5*(metadata_score)\n",
    "        combined[int(song)] = combined_score\n",
    "    return(np.array(sorted(combined.items(), key=lambda x: x[1], reverse=True))[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[530.  64.  22.  48.  89.  41.  99. 113.  32.  51.]\n"
     ]
    }
   ],
   "source": [
    "print(similarity(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
